{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.metadatasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadatasets: a dataset of datasets\n",
    "\n",
    "> This functionality will allow you to create a dataset from data stores in multiple, smaller datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I'd like to thank both Thomas Capelle (https://github.com/tcapelle)  and Xander Dunn (https://github.com/xanderdunn) for their contributions to make this code possible. \n",
    "* This functionality allows you to use multiple numpy arrays instead of a single one, which may be very useful in many practical settings. I've tested it with 10k+ datasets and it works well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tsai.imports import *\n",
    "from tsai.utils import *\n",
    "from tsai.data.validation import *\n",
    "from tsai.data.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSMetaDataset():\n",
    "    \" A dataset capable of indexing mutiple datasets at the same time\"\n",
    "    def __init__(self, dataset_list, **kwargs):\n",
    "        if not is_listy(dataset_list): dataset_list = [dataset_list]\n",
    "        self.datasets = dataset_list\n",
    "        self.split = kwargs['split'] if 'split' in kwargs else None            \n",
    "        self.mapping = self._mapping()\n",
    "        if hasattr(dataset_list[0], 'loss_func'): \n",
    "            self.loss_func =  dataset_list[0].loss_func\n",
    "        else: \n",
    "            self.loss_func = None\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.split is not None: \n",
    "            return len(self.split)\n",
    "        else:\n",
    "            return sum([len(ds) for ds in self.datasets])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split is not None: idx = self.split[idx]\n",
    "        idx = listify(idx)\n",
    "        idxs = self.mapping[idx]\n",
    "        idxs = idxs[idxs[:, 0].argsort()]\n",
    "        self.mapping_idxs = idxs\n",
    "        ds = np.unique(idxs[:, 0])\n",
    "        b = [self.datasets[d][idxs[idxs[:, 0] == d, 1]] for d in ds]\n",
    "        output = tuple(map(torch.cat, zip(*b)))\n",
    "        return output\n",
    "\n",
    "    def _mapping(self):\n",
    "        lengths = [len(ds) for ds in self.datasets]\n",
    "        idx_pairs = np.zeros((np.sum(lengths), 2)).astype(np.int32)\n",
    "        start = 0\n",
    "        for i,length in enumerate(lengths):\n",
    "            if i > 0: \n",
    "                idx_pairs[start:start+length, 0] = i\n",
    "            idx_pairs[start:start+length, 1] = np.arange(length)\n",
    "            start += length\n",
    "        return idx_pairs\n",
    "    \n",
    "    @property\n",
    "    def vars(self):\n",
    "        s = self.datasets[0][0][0] if not isinstance(self.datasets[0][0][0], tuple) else self.datasets[0][0][0][0]\n",
    "        return s.shape[-2]\n",
    "    @property\n",
    "    def len(self): \n",
    "        s = self.datasets[0][0][0] if not isinstance(self.datasets[0][0][0], tuple) else self.datasets[0][0][0][0]\n",
    "        return s.shape[-1]\n",
    "\n",
    "\n",
    "class TSMetaDatasets(FilteredBase):\n",
    "    def __init__(self, metadataset, splits):\n",
    "        store_attr()\n",
    "        self.mapping = metadataset.mapping\n",
    "    def subset(self, i):\n",
    "        return type(self.metadataset)(self.metadataset.datasets, split=self.splits[i])\n",
    "    @property\n",
    "    def train(self): \n",
    "        return self.subset(0)\n",
    "    @property\n",
    "    def valid(self): \n",
    "        return self.subset(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create 3 datasets. In this case they will have different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(#50) [(TSTensor(vars:5, len:50), TensorCategory(7)),(TSTensor(vars:5, len:50), TensorCategory(5)),(TSTensor(vars:5, len:50), TensorCategory(5)),(TSTensor(vars:5, len:50), TensorCategory(4)),(TSTensor(vars:5, len:50), TensorCategory(7)),(TSTensor(vars:5, len:50), TensorCategory(3)),(TSTensor(vars:5, len:50), TensorCategory(2)),(TSTensor(vars:5, len:50), TensorCategory(4)),(TSTensor(vars:5, len:50), TensorCategory(1)),(TSTensor(vars:5, len:50), TensorCategory(1))...],\n",
       " (#111) [(TSTensor(vars:5, len:50), TensorCategory(7)),(TSTensor(vars:5, len:50), TensorCategory(5)),(TSTensor(vars:5, len:50), TensorCategory(8)),(TSTensor(vars:5, len:50), TensorCategory(7)),(TSTensor(vars:5, len:50), TensorCategory(2)),(TSTensor(vars:5, len:50), TensorCategory(9)),(TSTensor(vars:5, len:50), TensorCategory(7)),(TSTensor(vars:5, len:50), TensorCategory(1)),(TSTensor(vars:5, len:50), TensorCategory(3)),(TSTensor(vars:5, len:50), TensorCategory(10))...],\n",
       " (#110) [(TSTensor(vars:5, len:50), TensorCategory(6)),(TSTensor(vars:5, len:50), TensorCategory(1)),(TSTensor(vars:5, len:50), TensorCategory(10)),(TSTensor(vars:5, len:50), TensorCategory(1)),(TSTensor(vars:5, len:50), TensorCategory(6)),(TSTensor(vars:5, len:50), TensorCategory(6)),(TSTensor(vars:5, len:50), TensorCategory(7)),(TSTensor(vars:5, len:50), TensorCategory(9)),(TSTensor(vars:5, len:50), TensorCategory(2)),(TSTensor(vars:5, len:50), TensorCategory(10))...]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = L(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])\n",
    "dsets = []\n",
    "for i in range(3):\n",
    "    size = np.random.randint(50, 150)\n",
    "    X = torch.rand(size, 5, 50)\n",
    "    y = vocab[torch.randint(0, 10, (size,))]\n",
    "    tfms = [None, TSClassification(add_na=True)]\n",
    "    dset = TSDatasets(X, y, tfms=tfms)\n",
    "    dsets.append(dset)\n",
    "dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.TSMetaDataset at 0x7fd719f0c950>, 5, 50)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadataset = TSMetaDataset(dsets)\n",
    "metadataset, metadataset.vars, metadataset.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll apply splits now to create train and valid metadatasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBwAAABTCAYAAAA82hSvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUWklEQVR4nO3da1CU5/nH8R/sQjhGORhQMB5AjEKIBTVSAtRaKzFokjH+o51YcabjaNsXCTp1HOrUZkKa6NSmZmxIpzNtaqbjoWptCEQz1tpEDTFiNGqIqMgZBJQALiDL7v+F404QFhH3pH4/r9hnn72va9fLm+Ha+7kfr5iYGKsAAAAAAAAcyNvdCQAAAAAAgPsPDQcAAAAAAOBwNBwAAAAAAIDD0XAAAAAAAAAOR8MBAAAAAAA4HA0HAAAAAADgcDQcAAAeycvLSxkZGVq3bp3++Mc/6vXXX1d2drYeeeSRQY+RlZWl3NxcSVJKSoo2bdo05HxSUlKUl5cnSYqLi1N+fr78/f2HPN535efn64knnpAk5eXlKSUlxSHj3hzvhz/8ocPGAwAAGCyjuxMAAKA/P/rRjzRr1izt2LFDtbW1Gj58uObMmaM1a9bot7/9rVpbW+9ovJKSEpWWltoe5+fn65133tHJkyfvOLeLFy8qNzdXnZ2dtz136dKl8vf3V35+vt1zcnNz7/j9DDbexo0bB5UnAACAo7HCAQDgkdLT0/Xhhx+qpKRE9fX1Ki0t1ZYtW2S1WpWUlHTH43V1denq1asOyc1sNqu5uVlWq/WuxvH2vvFruLm5Wd3d3Y5IrY+WlhYaDgAAwC1Y4QAA8EgBAQEKCwvrdcxsNuvtt9/WtWvXJN34Nt9oNOrq1atKTU1VV1eXDh06pH379vUZLyUlRQsXLlROTo7t2/+VK1eqoKBABQUFfc6fOHGiXnzxRY0YMUKVlZU6d+6c7bm4uDjl5OTolVdeUUdHh6ZNm6a5c+cqPDxcLS0tKioq0pEjR7R06VLb5RF5eXnKzc1VTk6OKisrFRoaqri4OK1evbrPaovw8HC98sorGjdunBobG7V3716dOnXKNs6BAwf0n//8R5IUFhamvLw8vfbaa5o1a1afeN8938vLS1lZWUpNTdVDDz2kiooK7dq1S1VVVZKknJwcXbp0SQEBAUpOTlZPT48OHDigoqKiof9DAgCABxYrHAAAHumLL75QZmamVq1apczMTMXGxspoNKqiokJNTU228773ve/J19dXGzdu1O7du/X000/rqaeeGnDsm/s6vP/++zpw4ECf54ODg7Vy5UqdO3dOb7zxho4ePapZs2b1O9bIkSOVnZ2toqIivfbaa/r444/10ksvafTo0frnP/+pkpISnT17Vhs3brS9JiMjQ5WVlb2Ofdfs2bNVUlKiN998U2fOnNGKFSs0atSo235m9uLdNHfuXKWlpWnbtm3asGGDysvLtWrVKoWEhNjOmTlzplpaWrRhwwYdPHhQzz77rCIjI28bGwAA4FascAAAeKTt27ervr5eU6dO1bx582QwGNTZ2amjR49q586dslgskqTW1lZt375dVqtV9fX1GjdunDIyMvTpp5/aHbu5uVmS1NbWpo6Ojj7Pp6Wl6erVq9q2bZskqaamRtHR0Xr88cf7nHtzE8tLly7p8uXLamhokMlk0vXr13Xt2jV1dXXJ29tbLS0tttecP39eH330kd38Pv30Ux06dEiStHv3bk2ePFlPPfWUduzYMeBnZi+eJBmNRs2ePVvbt2/Xl19+KUnau3evJk6cqJkzZ2r37t2293FzxUdhYaEyMzMVFRWl+vr6AWMDAADcioYDAMAjWSwWHTx4UAcPHpSPj4/Gjx+v6dOnKyMjQ21tbSosLJQkVVZW9tpLobq6WqmpqXcVOzo6WhcvXux1rKKiot+GQ2lpqc6fP69169aprKxM586d04kTJ9TQ0GB3/Lq6ugHjX7p0qc/j8PDwwb+BfoSHh8vPz6/XpSHSjc8rIiKi1+ObrFaruru75evre1exAQDAg4mGAwDA44wfP17p6en629/+Jknq7u7WN998o2+++UYGg0GPPfaYreHQn7vdzNFgMPQ5dnODx1t1dXXpD3/4g0aPHq1JkyZp8uTJmj9/vv785z/bVhLcaX63Pm8wGHT9+vV+zzUaB/er3MfHR5LU09PT67ivr2+vsW+uHAEAALhb7OEAAPA4ZrNZM2bM6HffguvXr/f6AzkqKqrX8+PHj7/tCoLbqaur07hx4/qM25/k5GRlZmaqqqpK+/fv11tvvaUzZ85oypQpQ44/duzYPo9ramok3fhsbjYPJA16f4XGxkb19PT0eV+xsbG9VjUAAAA4Cg0HAIDHqays1FdffaUVK1YoKSlJERERio2NVVZWllJSUvS///3Pdm5YWJief/55jRw5UmlpaZoxY4Zt/4OBdHd3KyoqSgEBAX2eO3TokMLDw7Vw4UJFRUUpLS3NbgPBZDLpmWeeUWpqqiIjI5WYmKixY8eqvLzcFickJOSOLon4/ve/ryeffFKjRo3SggULFBISok8++UTSjWZIYmKifH19FRQUpDlz5vR5X/3F6+zs1OHDh/XCCy8oISFBo0eP1k9+8hP5+/vbxgYAAHAkLqkAAHikd999V7NmzdIzzzyj8PBwdXZ2qry8XJs3b1ZZWZntvLNnzyowMFBr1qyRyWTSnj17VFxcfNvxjxw5oqefflpms1n79+/v9dzVq1f1zjvv6MUXX1R6errKysr0r3/9S5mZmX3G+frrr7Vnzx7NmTNHw4cPV1tbmw4dOmRrihw/flxJSUn6+c9/rldffXVQ772wsFDp6el69NFH1dDQoC1btqi9vV3SjU0kly1bpo0bN+rKlSsqKirqtfpioHg7d+6UJC1btkw+Pj6qqKjQ5s2bZTKZBpUXAADAnfCKiYm5uwtdAQBwk6VLl8rf31/5+fnuTgUAAAC34JIKAAAAAADgcDQcAAAAAACAw3FJBQAAAAAAcDhWOAAAAAAAAIdz2V0q/Pz8FB0drba2NvX09LgqLAAAAADABQwGg4KDg1VdXa3Ozk53pwMP4LKGQ3R0tGbOnOmqcAAAAAAANzh48KDOnz/v7jTgAVzWcGhra5MkbduWpcbGMFeFBQAAAO4Jj73/krtTAO5K8LVgzTg9w/a3H+CyhsPNyygaG8NUUxPpqrAAAADAPSHi4avuTgFwCC6hx01sGgkAAAAAAByOhgMAAAAAAHA4l11SAQAAAADAvcRoNMrf39/daXikjo4Omc3mAc9hhQMAAAAAALeIjo5WWBg3PLAnLCxM0dHRA57DCgcAAAAAAL7DaDSqu7tbDQ0N7k7FY7W1tSkyMlJGo9HuSgdWOAAAAAAA8B3+/v4ymUzuTsPjmUymAS85GXTDITs7W6mpqQ5JCgAAAAAA3NusVuuAz9/2kor4+HjFx8dr+vTpKisrc1hiAAAAAADg/nXbhsOYMWNkNBrV2trqinwAAAAAAPBIFy6cd3qMmJhYp8dwlds2HAoLCyVJkZGRTk8GAAAAAAAMzssvv6wJEyZIkgwGgywWi+0yh88++0xbt24d1DgTJkxQdna2cnNzHZqfU+5SkZWVpaysrF7Hrl27ptLSUmeEAwAAAADggfPWW2/Zfs7JydG5c+dUUFDQ5zxvb29ZLBa745SVlTm82SA5qeFQUFDQ502Gh4fr+eefd0Y4AAAAAADwHSkpKZoxY4ZaWlo0ZswYrV+/XlOnTtX8+fM1fPhwNTc3a+/evfryyy8VFxenZcuWae3atcrKylJERIS8vLw0adIkmUwm/fWvf9XFixfvOAduiwkAAAAAwH1owoQJKi0t1auvviofHx/99Kc/1XvvvaeXX35Z+/fv15IlS/p9XVJSkj7//HOtWbNGpaWlmj9//pDi03AAAAAAAOA+1NDQoKNHj9r2dti4caMuXLigoKAgeXl5KTAwUN7efdsCpaWlOnXqlMxms06cOKHQ0NAhxXfKJRUAAAAAAMC9rl27ZvvZarUqIyNDCQkJunLlihoaGuy+rr293fazxWKRwWAYUvxBNxw2bdo0pAAAAAAAAMC9nnzyST366KP69a9/LbPZrOjoaKWkpDg1JiscAAAAAAC4zxkMBnl7e8vHx0fDhw/XvHnzJElGo/PaAjQcAAAAAAAYhJiYWHenMGSfffaZEhIS9Oabb6qxsVG7d+/WsGHDtHz5cu3fv98pMb1iYmKsThn5Fjdvi/n220tVUxPpipAAAADAPSPpeLK7UwDuSkhriGYXz9aePXvU1NTk7nTuSnBwsCSpra3NzZl4ttt9TtylAgAAAAAAOBwNBwAAAAAA4HA0HAAAAAAAgMPRcAAAAAAAAA7nsrtUGAwGSdKIEc2uCgkAAADcM0JaQ9ydAnBXgq/d2EDw5t9+gMsaDjd3r1y0qMBVIQEAAIB7R/Fsd2cAOERwcLAaGhrcnQY8gMsaDtXV1Ro7dqw2b96snp4eV4UFBrR27Vr97ne/c3cagA01CU9CPcLTUJPwNNRkbwaDQcHBwaqurnZ3KvAQLms4dHZ2KiwsjE4XPEpgYOA9f49g3F+oSXgS6hGehpqEp6Em+7rf/94btmOY02N8+3/fOj2Gq7BpJAAAAAAA96C5c+fqN7/5TZ/jycnJ2rx5s/z8/Oy+NicnR6mpqZKkLVu2KDw8vN/z8vLyFBcXN6T8aDgAAAAAAHAPKi4uVkREhEaNGtXreHJysk6ePKnOzs5BjfOLX/zCKat1XHZJBQAAAAAAcJzm5mZduHBBU6dO1b///W9Jkq+vrxISEvTuu+8qNDRUS5Ys0fjx49XV1aWSkhLt2LFDFoul1zj5+flat26dGhsblZycrAULFiggIEDFxcXy8vIacn4uXeFQUMAdKuBZqEl4GmoSnoR6hKehJuFpqEl4guLiYiUnJ9seJyYmqqOjQ2fPntWzzz6r2tparVq1Sm+88YYSExP1+OOP2x0rJCRES5Ys0T/+8Q/96le/kslkUmho6JBzo+GABxo1CU9DTcKTUI/wNNQkPA01CU9w/PhxhYaGavTo0ZKkpKQkff7557Jarfroo4/0wQcfyGAwKDAwUGazWUFBQXbHmjZtms6cOaPTp0/r+vXr+uCDD9TR0THk3LikAgAAAACAe1RHR4dOnTql5ORkXb58WQkJCdqwYYMkKSoqSitXrlRPT49qampue3lEWFiYmpubbY8tFova2tqGnBsNBwAAAAAA7mHFxcVauHChqqurdfnyZVVXV8vHx0dLly7Vpk2bVF5eLknKzc0dcJzW1tZeG1AajUY9/PDDQ86Lu1QAAAAAAHAPO336tPz8/JSVlaXi4mJJkre3t7y9veXj4yM/Pz9lZGRo1KhRMhrtrzs4fvy44uPjNXnyZPn6+mr+/Pny9fUdcl6scAAAAAAAYBC+/b9v3Z1CvywWi7744gulp6fbGg5dXV3avn27li9fLkk6cuSI9uzZowULFujkyZP9jlNfX6+tW7dq8eLFCgoK0ieffKKampoh5+UVExNjHfKrAQAAAAC4zwQHB0vSXe1f8CC43efkkhUOsbGxWrx4sUaMGKGKigpt3bpVly9fdkVoQJK0YsUKxcfH2x63t7dr7dq11CZcLjs7W2VlZTp8+LCkgedH6hOucGtN2psvJWoSzjV58mQtWLBAI0aM0JUrV/Thhx/q2LFjzJNwG3s1yTwJDJ7TGw5+fn5asWKFdu3apRMnTmj27Nn62c9+ptdff93ZoQGbiIgIrV+/vteOq9QmXCk+Pl7x8fGaPn26ysrKJA1cg9QnnK2/mpT6ny8l5kw4V2BgoJYvX64dO3bo2LFjeuyxx7R8+XLV1tYyT8ItBqpJ5klg8Jy+aeQTTzyhpqYmHT16VJ2dnSosLFRkZKRGjhzp7NCAzbBhw3TlypVex6hNuNKYMWNkNBrV2tpqOzZQDVKfcLb+alLqf76UmDPhXBMmTFBzc7OOHDmi7u5uffXVV6qtrdWUKVOYJ+EW9mpy0qRJzJPAHXD6Cofo6GhVVlbaHvf09KihoUGPPPKI6urqnB0eUEhIiKxWq1avXq2RI0eqvr5eO3fupDbhUoWFhZKkyMhI27GBapD6hLP1V5P25svy8nJqEk51/vx5/eUvf7E9DgwMVHh4uGbMmKGvv/7adpx5Eq5irybb2tqYJ4Hv8PLyktVqf1tIpzcc/P391d7e3utYZ2en/Pz8nB0akCQFBQWptrZWu3btUk1NjVJTU/XLX/5SJ0+e7PPNHrUJVxpofmTuhDvYmy/Xr19PTcKp2tvbbfUVGxurJUuWqKqqSk1NTTKZTL3OZZ6EK9irybq6OubJB0RHR4fCwsLYNPI2AgIC1NTUZPd5pzccTCZTn/t2PvTQQ31+eQDOUlVVpd///ve2x//973+Vlpam2NhYnT59ute51CZcaaD5kbkT7jDQfElNwtn8/Py0aNEiTZkyRfv27dO+ffv03HPPMU/CbfqrSYvFwjz5gDCbzfLx8VFkZKRMJtOA3+I/iLy8vBQQECCj0Siz2Wz3PKfv4VBXV6fo6GjbY4PBoBEjRqiqqsrZoQFJN3YYTkxM7HXMYDDo448/pjbhVgPNj8ydcAd782VXVxc1Cafy8fHR6tWr9fDDD2v9+vUqKiqSxWJhnoTb2KtJ5skHS3V1tZqammg29MNqtaqpqUnV1dUDnuf0FQ4nTpzQCy+8oMTERJWWlmrevHm6dOmSWlpanB0akHSjs7xo0SK1tLSorq5Oqamp8vX11bFjx/Tcc89Rm3CbgeZH5k64g735sqysTAaDgZqE00ybNk1Go1F/+tOfen1TxjwJd7FXk8yTDx6z2cxlFXfBKyYmxuntmokTJ2rx4sUKDQ3VhQsX9N577/EfDy714x//WD/4wQ/k7++vyspKbdu2TXV1ddQmXC4nJ0fFxcU6fPiwpIHnR+oTrnBrTdqbLyVqEs6zaNEipaen9/kW8e9//7taWlqYJ+FyA9XksGHDmCeBQXJJwwEAAAAAADxYnL6HAwAAAAAAePDQcAAAAAAAAA5HwwEAAAAAADgcDQcAAAAAAOBwNBwAAAAAAIDD0XAAAAAAAAAOR8MBAAAAAAA4HA0HAAAAAADgcDQcAAAAAACAw/0/fwxgX1szTegAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x36 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((#217) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#54) [217,218,219,220,221,222,223,224,225,226...])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = TimeSplitter()(metadataset)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.TSMetaDataset at 0x7fd71a120a90>,\n",
       " <__main__.TSMetaDataset at 0x7fd71a120e90>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatasets = TSMetaDatasets(metadataset, splits=splits)\n",
    "metadatasets.train, metadatasets.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor(samples:64, vars:5, len:50),\n",
       " TensorCategory([ 7,  4,  9,  2,  3,  2, 10,  6,  1, 10,  7,  3,  9,  9,  7,  3,  2,  2,\n",
       "          5,  3,  5,  5,  3,  7,  7, 10,  4,  3,  3,  1, 10,  3,  9,  6,  4,  4,\n",
       "          7,  2,  4,  8,  2,  9,  4,  5,  3,  7, 10,  9,  9, 10,  7,  9,  3, 10,\n",
       "          7,  5,  6,  6, 10,  5,  8,  9,  8,  5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = TSDataLoaders.from_dsets(metadatasets.train, metadatasets.valid)\n",
    "xb, yb = first(dls.train)\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There also en easy way to map any particular sample in a batch to the original dataset and id: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TSDataLoaders.from_dsets(metadatasets.train, metadatasets.valid)\n",
    "xb, yb = first(dls.train)\n",
    "mappings = dls.train.dataset.mapping_idxs\n",
    "for i, (xbi, ybi) in enumerate(zip(xb, yb)):\n",
    "    ds, idx = mappings[i]\n",
    "    test_close(dsets[ds][idx][0].data, xbi)\n",
    "    test_close(dsets[ds][idx][1].data, ybi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example the 3rd sample in this batch would be: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 38], dtype=int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.train.dataset.mapping_idxs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 000_utils.ipynb.\n",
      "Converted 000b_data.validation.ipynb.\n",
      "Converted 000c_data.preparation.ipynb.\n",
      "Converted 001_data.external.ipynb.\n",
      "Converted 002_data.core.ipynb.\n",
      "Converted 002b_data.unwindowed.ipynb.\n",
      "Converted 002c_data.metadatasets.ipynb.\n",
      "Converted 003_data.preprocessing.ipynb.\n",
      "Converted 003b_data.transforms.ipynb.\n",
      "Converted 003c_data.mixed_augmentation.ipynb.\n",
      "Converted 003d_data.image.ipynb.\n",
      "Converted 003e_data.features.ipynb.\n",
      "Converted 005_data.tabular.ipynb.\n",
      "Converted 006_data.mixed.ipynb.\n",
      "Converted 050_losses.ipynb.\n",
      "Converted 051_metrics.ipynb.\n",
      "Converted 052_learner.ipynb.\n",
      "Converted 052b_tslearner.ipynb.\n",
      "Converted 053_optimizer.ipynb.\n",
      "Converted 060_callback.core.ipynb.\n",
      "Converted 061_callback.noisy_student.ipynb.\n",
      "Converted 063_callback.MVP.ipynb.\n",
      "Converted 064_callback.PredictionDynamics.ipynb.\n",
      "Converted 100_models.layers.ipynb.\n",
      "Converted 100b_models.utils.ipynb.\n",
      "Converted 100c_models.explainability.ipynb.\n",
      "Converted 101_models.ResNet.ipynb.\n",
      "Converted 101b_models.ResNetPlus.ipynb.\n",
      "Converted 102_models.InceptionTime.ipynb.\n",
      "Converted 102b_models.InceptionTimePlus.ipynb.\n",
      "Converted 103_models.MLP.ipynb.\n",
      "Converted 103b_models.FCN.ipynb.\n",
      "Converted 103c_models.FCNPlus.ipynb.\n",
      "Converted 104_models.ResCNN.ipynb.\n",
      "Converted 105_models.RNN.ipynb.\n",
      "Converted 105_models.RNNPlus.ipynb.\n",
      "Converted 106_models.XceptionTime.ipynb.\n",
      "Converted 106b_models.XceptionTimePlus.ipynb.\n",
      "Converted 107_models.RNN_FCN.ipynb.\n",
      "Converted 107b_models.RNN_FCNPlus.ipynb.\n",
      "Converted 108_models.TransformerModel.ipynb.\n",
      "Converted 108b_models.TST.ipynb.\n",
      "Converted 108c_models.TSTPlus.ipynb.\n",
      "Converted 109_models.OmniScaleCNN.ipynb.\n",
      "Converted 110_models.mWDN.ipynb.\n",
      "Converted 111_models.ROCKET.ipynb.\n",
      "Converted 111b_models.MINIROCKET.ipynb.\n",
      "Converted 111c_models.MINIROCKET_Pytorch.ipynb.\n",
      "Converted 111d_models.MINIROCKETPlus_Pytorch.ipynb.\n",
      "Converted 112_models.XResNet1d.ipynb.\n",
      "Converted 112b_models.XResNet1dPlus.ipynb.\n",
      "Converted 113_models.TCN.ipynb.\n",
      "Converted 114_models.XCM.ipynb.\n",
      "Converted 114b_models.XCMPlus.ipynb.\n",
      "Converted 120_models.TabModel.ipynb.\n",
      "Converted 121_models.TabTransformer.ipynb.\n",
      "Converted 122_models.TabFusionTransformer.ipynb.\n",
      "Converted 123_models.TSPerceiver.ipynb.\n",
      "Converted 124_models.TSiTPlus.ipynb.\n",
      "Converted 130_models.MultiInputNet.ipynb.\n",
      "Converted 140_models.misc.ipynb.\n",
      "Converted 900_tutorials.ipynb.\n",
      "Converted index.ipynb.\n",
      "\n",
      "\n",
      "Checking folder: /Users/nacho/Documents/Machine_Learning/Jupyter_Notebooks/tsai/tsai\n",
      "Correct conversion! 😃\n",
      "Total time elapsed 241 s\n",
      "Thursday 26/08/21 20:13:29 CEST\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "out = create_scripts(); beep(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
